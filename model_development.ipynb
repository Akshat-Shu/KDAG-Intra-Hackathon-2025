{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gdown\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# --- 1. Data Loading ---\n",
    "if not os.path.exists('Download'):\n",
    "    print('Downloading data...')\n",
    "    gdown.download_folder('https://drive.google.com/drive/folders/1UKUZZ6uTdEVdGWEKNh0ZRp08pK_AVnrm', output='Download')\n",
    "else:\n",
    "    print('Data already downloaded.')\n",
    "\n",
    "df = pd.read_csv('Download/subject_data.csv', low_memory=False)\n",
    "images_file = h5py.File('Download/images.hdf5', 'r')\n",
    "\n",
    "print('Data loaded successfully.')\n",
    "print(f'Tabular data shape: {df.shape}')\n",
    "print(f'Number of images in HDF5 file: {len(images_file.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Feature Selection and Preprocessing ---\n",
    "\n",
    "# Define feature sets based on notebook exploration\n",
    "lesion_geometry = [\n",
    "    'clin_size_long_diam_mm',\n",
    "    'tbp_lv_areaMM2',\n",
    "    'tbp_lv_perimeterMM',\n",
    "    'tbp_lv_minorAxisMM',\n",
    "    'tbp_lv_eccentricity',\n",
    "    'tbp_lv_area_perim_ratio',\n",
    "    'tbp_lv_norm_border',\n",
    "    'tbp_lv_symm_2axis',\n",
    "    'tbp_lv_symm_2axis_angle',\n",
    "]\n",
    "\n",
    "lesion_color_texture = [\n",
    "    'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext',\n",
    "    'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L',\n",
    "    'tbp_lv_Lext', 'tbp_lv_color_std_mean', 'tbp_lv_deltaA', 'tbp_lv_deltaB',\n",
    "    'tbp_lv_deltaL', 'tbp_lv_deltaLBnorm', 'tbp_lv_norm_color',\n",
    "    'tbp_lv_radial_color_std_max', 'tbp_lv_stdL', 'tbp_lv_stdLExt',\n",
    "]\n",
    "\n",
    "numerical_features = ['age_approx'] + lesion_geometry + lesion_color_texture\n",
    "categorical_features = ['sex', 'tbp_lv_location']\n",
    "\n",
    "# Handle missing values\n",
    "df['age_approx'].fillna(df['age_approx'].median(), inplace=True)\n",
    "df['sex'].fillna('unknown', inplace=True)\n",
    "# For tbp_lv_location, the notebook showed no NaNs, but we'll add a fillna for robustness\n",
    "df['tbp_lv_location'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Create the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "print('Preprocessing pipeline created.')\n",
    "\n",
    "# Fit and transform the data\n",
    "X_tabular = preprocessor.fit_transform(df)\n",
    "y = df['target'].values\n",
    "\n",
    "print(f'Shape of preprocessed tabular data (X): {X_tabular.shape}')\n",
    "print(f'Shape of target variable (y): {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Add a function to get images, which will be needed by the PyTorch Dataset later\n",
    "def get_img(isic_id):\n",
    "    \"\"\"Loads image from HDF5 file and returns as PIL Image.\"\"\"\n",
    "    try:\n",
    "        # The image data is stored as a byte array, so we use io.BytesIO\n",
    "        image_data = images_file[isic_id][()]\n",
    "        image = Image.open(io.BytesIO(image_data)).convert('RGB')\n",
    "        return image\n",
    "    except KeyError:\n",
    "        # Return a blank image if the ID is not found\n",
    "        return Image.new('RGB', (100, 100), color = 'red')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Baseline Model (XGBoost on Tabular Data) ---\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "print('Starting baseline model training...')\n",
    "\n",
    "# Calculate scale_pos_weight for handling class imbalance\n",
    "scale_pos_weight = np.sum(y == 0) / np.sum(y == 1)\n",
    "print(f'Calculated scale_pos_weight: {scale_pos_weight:.2f}')\n",
    "\n",
    "# Setup Stratified K-Fold Cross-Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "auc_scores = []\n",
    "\n",
    "X_tabular_dense = X_tabular.toarray() # Convert to dense array for XGBoost\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(X_tabular_dense, y)):\n",
    "    print(f'--- Fold {fold+1}/{n_splits} ---')\n",
    "    X_train, X_val = X_tabular_dense[train_index], X_tabular_dense[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    # Initialize and train the XGBoost model\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        use_label_encoder=False, # Deprecated\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities and calculate AUC\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    auc_scores.append(auc)\n",
    "    print(f'AUC for fold {fold+1}: {auc:.4f}')\n",
    "\n",
    "print('\\n--- Cross-Validation Results ---')\n",
    "print(f'Mean AUC: {np.mean(auc_scores):.4f}')\n",
    "print(f'Standard Deviation of AUC: {np.std(auc_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Advanced Multi-modal Model --- \n",
    "# First, let's set up the PyTorch environment, Dataset, and DataLoaders\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import timm # PyTorch Image Models library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(F_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "# Custom PyTorch Dataset\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, dataframe, tabular_data, image_getter, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.tabular_data = torch.tensor(tabular_data.toarray(), dtype=torch.float32)\n",
    "        self.image_getter = image_getter\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        isic_id = row['isic_id']\n",
    "        image = self.image_getter(isic_id)\n",
    "        tabular = self.tabular_data[idx]\n",
    "        label = torch.tensor(row['target'], dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return {'image': image, 'tabular': tabular}, label\n",
    "\n",
    "# Data Augmentation and Normalization\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Stratified Split for train/val/test\n",
    "train_val_df, test_df, X_train_val_tab, X_test_tab, y_train_val, y_test = train_test_split(\n",
    "    df, X_tabular, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "train_df, val_df, X_train_tab, X_val_tab, y_train, y_val = train_test_split(\n",
    "    train_val_df, X_train_val_tab, y_train_val, test_size=0.18, random_state=42, stratify=y_train_val # 0.18 * 0.85 = ~0.15\n",
    ")\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = MultiModalDataset(train_df, X_train_tab, get_img, transform=train_transform)\n",
    "val_dataset = MultiModalDataset(val_df, X_val_tab, get_img, transform=val_transform)\n",
    "test_dataset = MultiModalDataset(test_df, X_test_tab, get_img, transform=val_transform)\n",
    "\n",
    "# WeightedRandomSampler for training to handle imbalance\n",
    "class_weights = compute_sample_weight(class_weight='balanced', y=train_df['target'])\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(class_weights), len(class_weights), replacement=True)\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f'Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}, Test samples: {len(test_dataset)}')\n",
    "print('DataLoaders created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Model Architecture (Cross-Attention) ---\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, in_dim_q, in_dim_kv, out_dim, num_heads=4):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = out_dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "        self.to_q = nn.Linear(in_dim_q, out_dim, bias=False)\n",
    "        self.to_kv = nn.Linear(in_dim_kv, out_dim * 2, bias=False)\n",
    "        self.to_out = nn.Linear(out_dim, out_dim)\n",
    "\n",
    "    def forward(self, q, kv):\n",
    "        q = self.to_q(q)\n",
    "        k, v = self.to_kv(kv).chunk(2, dim=-1)\n",
    "        \n",
    "        # Reshape for multi-head attention\n",
    "        b, _, n, _ = q.shape\n",
    "        q = q.view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        attn_scores = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = F.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        out = (attn @ v).transpose(1, 2).reshape(b, n, -1)\n",
    "        \n",
    "        return self.to_out(out)\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, image_backbone_name, tabular_in_features, num_classes=2):\n",
    "        super(MultiModalModel, self).__init__()\n",
    "        # Image Branch\n",
    "        self.image_backbone = timm.create_model(image_backbone_name, pretrained=True, num_classes=0) # num_classes=0 removes head\n",
    "        image_out_features = self.image_backbone.num_features\n",
    "        \n",
    "        # Tabular Branch\n",
    "        self.tabular_mlp = nn.Sequential(\n",
    "            nn.Linear(tabular_in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "        tabular_out_features = 256\n",
    "        \n",
    "        # Cross-Attention Fusion\n",
    "        self.img_to_tab_attn = CrossAttention(image_out_features, tabular_out_features, 128)\n",
    "        self.tab_to_img_attn = CrossAttention(tabular_out_features, image_out_features, 128)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(image_out_features + tabular_out_features + 256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        image_features = self.image_backbone(x['image'])\n",
    "        tabular_features = self.tabular_mlp(x['tabular'])\n",
    "        \n",
    "        # Add sequence dimension for attention\n",
    "        img_q = image_features.unsqueeze(1)\n",
    "        tab_q = tabular_features.unsqueeze(1)\n",
    "        \n",
    "        img_attended = self.tab_to_img_attn(tab_q, img_q).squeeze(1)\n",
    "        tab_attended = self.img_to_tab_attn(img_q, tab_q).squeeze(1)\n",
    "        \n",
    "        # Fusion\n",
    "        combined_features = torch.cat([image_features, tabular_features, img_attended, tab_attended], dim=1)\n",
    "        \n",
    "        output = self.classifier(combined_features)\n",
    "        return output\n",
    "\n",
    "print('Model architecture defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Training and Evaluation Loop ---\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, model_name):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = FocalLoss(alpha=0.75, gamma=2.0) # Higher alpha for the positive class\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.5)\n",
    "    \n",
    "    best_val_auc = 0.0\n",
    "    epochs = 5 # A smaller number of epochs for this demonstration\n",
    "    \n",
    "    print(f'\\n--- Starting Training for {model_name} ---')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]', leave=False)\n",
    "        for data, target in progress_bar:\n",
    "            image, tabular = data['image'].to(device), data['tabular'].to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model({'image': image, 'tabular': tabular})\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]', leave=False):\n",
    "                image, tabular = data['image'].to(device), data['tabular'].to(device)\n",
    "                output = model({'image': image, 'tabular': tabular})\n",
    "                val_preds.extend(output.softmax(1)[:, 1].cpu().numpy())\n",
    "                val_targets.extend(target.cpu().numpy())\n",
    "        \n",
    "        val_auc = roc_auc_score(val_targets, val_preds)\n",
    "        scheduler.step(val_auc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} | Train Loss: {train_loss/len(train_loader):.4f} | Val AUC: {val_auc:.4f}')\n",
    "        \n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            torch.save(model.state_dict(), f'{model_name}_best.pth')\n",
    "            print(f'   -> New best model saved with AUC: {val_auc:.4f}')\n",
    "            \n",
    "    return best_val_auc\n",
    "\n",
    "# --- 7. Instantiate and Train Models ---\n",
    "tabular_input_dim = X_train_tab.toarray().shape[1]\n",
    "\n",
    "# Model A: ConvNeXt\n",
    "convnext_model = MultiModalModel('convnext_tiny.in12k_ft_in1k', tabular_input_dim)\n",
    "best_auc_convnext = train_and_evaluate(convnext_model, train_loader, val_loader, 'convnext')\n",
    "\n",
    "# Model B: Vision Transformer (ViT)\n",
    "vit_model = MultiModalModel('vit_base_patch16_224.augreg_in21k', tabular_input_dim)\n",
    "best_auc_vit = train_and_evaluate(vit_model, train_loader, val_loader, 'vit')\n",
    "\n",
    "print('\\n--- Training Complete ---')\n",
    "print(f'Best ConvNeXt AUC: {best_auc_convnext:.4f}')\n",
    "print(f'Best ViT AUC: {best_auc_vit:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Final Evaluation on Test Set ---\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_final_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds_proba = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            image, tabular = data['image'].to(device), data['tabular'].to(device)\n",
    "            output = model({'image': image, 'tabular': tabular})\n",
    "            all_preds_proba.extend(output.softmax(1)[:, 1].cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    return all_targets, all_preds_proba\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "results = {}\n",
    "\n",
    "# Evaluate ConvNeXt\n",
    "print('Evaluating ConvNeXt model...')\n",
    "convnext_model.load_state_dict(torch.load('convnext_best.pth'))\n",
    "convnext_model.to(device)\n",
    "targets_cn, preds_proba_cn = evaluate_final_model(convnext_model, test_loader, device)\n",
    "preds_cn = (np.array(preds_proba_cn) > 0.5).astype(int)\n",
    "results['ConvNeXt'] = {\n",
    "    'AUC': roc_auc_score(targets_cn, preds_proba_cn),\n",
    "    'Precision': precision_score(targets_cn, preds_cn),\n",
    "    'Recall': recall_score(targets_cn, preds_cn),\n",
    "    'F1': f1_score(targets_cn, preds_cn)\n",
    "}\n",
    "print(classification_report(targets_cn, preds_cn, target_names=['Benign', 'Malignant']))\n",
    "\n",
    "# Evaluate ViT\n",
    "print('Evaluating ViT model...')\n",
    "vit_model.load_state_dict(torch.load('vit_best.pth'))\n",
    "vit_model.to(device)\n",
    "targets_vit, preds_proba_vit = evaluate_final_model(vit_model, test_loader, device)\n",
    "preds_vit = (np.array(preds_proba_vit) > 0.5).astype(int)\n",
    "results['ViT'] = {\n",
    "    'AUC': roc_auc_score(targets_vit, preds_proba_vit),\n",
    "    'Precision': precision_score(targets_vit, preds_vit),\n",
    "    'Recall': recall_score(targets_vit, preds_vit),\n",
    "    'F1': f1_score(targets_vit, preds_vit)\n",
    "}\n",
    "print(classification_report(targets_vit, preds_vit, target_names=['Benign', 'Malignant']))\n",
    "\n",
    "# Evaluate XGBoost Baseline\n",
    "print('Evaluating XGBoost baseline model...')\n",
    "xgb_final = xgb.XGBClassifier(objective='binary:logistic', scale_pos_weight=scale_pos_weight, use_label_encoder=False, random_state=42)\n",
    "xgb_final.fit(X_train_val_tab.toarray(), y_train_val)\n",
    "xgb_preds_proba = xgb_final.predict_proba(X_test_tab.toarray())[:, 1]\n",
    "xgb_preds = (xgb_preds_proba > 0.5).astype(int)\n",
    "results['XGBoost'] = {\n",
    "    'AUC': roc_auc_score(y_test, xgb_preds_proba),\n",
    "    'Precision': precision_score(y_test, xgb_preds),\n",
    "    'Recall': recall_score(y_test, xgb_preds),\n",
    "    'F1': f1_score(y_test, xgb_preds)\n",
    "}\n",
    "print(classification_report(y_test, xgb_preds, target_names=['Benign', 'Malignant']))\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print('\\n--- Final Model Comparison ---')\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Based on the evaluation metrics from the test set, the best performing model can be selected. Key metrics to consider are AUC, which gives a general measure of model quality, and Recall, which is critical in this medical context to minimize the number of missed malignant cases (false negatives). The F1-score provides a good balance between Precision and Recall.\n",
    "\n",
    "The final `results_df` dataframe provides a clear summary to make an informed decision."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
